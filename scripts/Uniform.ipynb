{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b566487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5252fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Volumes/MOOC/flipped/apr21-feature-mooc-flipped/\"\n",
    "week_type = \"eq_week\"\n",
    "feature_types = ['akpinar_et_al', 'boroujeni_et_al', \n",
    "                 'chen_cui', 'he_et_al', 'lalle_conati','lemay_doleck', \n",
    "                 'marras_et_al', 'mbouzao_et_al', 'mubarak_et_al', 'wan_et_al']\n",
    "marras_et_al_id = feature_types.index('marras_et_al')\n",
    "akpinar_et_al_id = feature_types.index('akpinar_et_al')\n",
    "course = \"epflx_algebre2x\"\n",
    "num_f = 50\n",
    "num_p = 50\n",
    "remove_obvious = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4bbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNaN(feature):\n",
    "    shape = feature.shape\n",
    "    feature_min = np.nanmin(\n",
    "        feature.reshape(-1, shape[2]), axis=0\n",
    "    )  # min of that feature over all weeks\n",
    "    feature = feature.reshape(-1, shape[2])\n",
    "    inds = np.where(np.isnan(feature))\n",
    "    feature[inds] = np.take(feature_min.reshape(-1), inds[1])\n",
    "    feature = feature.reshape(shape)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4d537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(feature):\n",
    "    id = feature.find('<')\n",
    "    if id==-1:\n",
    "        return feature\n",
    "    fct = feature[id+9:id+14].strip()\n",
    "    return feature[0:id]+fct\n",
    "\n",
    "def clean_akp_name(feature):\n",
    "    feature = feature.lower()\n",
    "    if feature.find(\"(\")!=-1:\n",
    "        feature = feature[1:-1]\n",
    "        feature = feature.replace(', ', '-')\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3f96ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 16, 347)\n",
      "(2720, 347)\n",
      "(170, 16, 3)\n",
      "(2720, 3)\n",
      "(170, 16, 13)\n",
      "(2720, 13)\n",
      "(170, 16, 3)\n",
      "(2720, 3)\n",
      "(170, 16, 22)\n",
      "(2720, 22)\n",
      "(170, 16, 10)\n",
      "(2720, 10)\n",
      "(170, 16, 12)\n",
      "(2720, 12)\n",
      "(170, 16, 3)\n",
      "(2720, 3)\n",
      "(170, 16, 13)\n",
      "(2720, 13)\n",
      "(170, 16, 14)\n",
      "(2720, 14)\n",
      "course:  epflx_algebre2x\n",
      "week_type:  eq_week\n",
      "feature_type:  ['akpinar_et_al', 'boroujeni_et_al', 'chen_cui', 'he_et_al', 'lalle_conati', 'lemay_doleck', 'marras_et_al', 'mbouzao_et_al', 'mubarak_et_al', 'wan_et_al']\n"
     ]
    }
   ],
   "source": [
    "# Loading the features\n",
    "feature_list = {}\n",
    "\n",
    "feature_type_list = []\n",
    "for feature_type in feature_types:\n",
    "\n",
    "    filepath = data_path + week_type + '-' + feature_type + '-' + course\n",
    "    feature_current = np.load(filepath+'/feature_values.npz')['feature_values']\n",
    "    print(feature_current.shape)\n",
    "    feature_norm = feature_current.reshape(-1,feature_current.shape[2] )\n",
    "    print(feature_norm.shape)\n",
    "    feature_type_list.append(pd.DataFrame(feature_norm))\n",
    "feature_list[course] = feature_type_list\n",
    "\n",
    "print('course: ', course)\n",
    "print('week_type: ', week_type)\n",
    "print('feature_type: ', feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1de6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akpinar_et_al 13\n",
      "boroujeni_et_al 3\n",
      "chen_cui 13\n",
      "he_et_al 3\n",
      "lalle_conati 22\n",
      "lemay_doleck 10\n",
      "marras_et_al 7\n",
      "mbouzao_et_al 3\n",
      "mubarak_et_al 13\n",
      "wan_et_al 13\n",
      "['competency_anticipation' 'content_alignment' 'content_anticipation'\n",
      " 'student_speed']\n"
     ]
    }
   ],
   "source": [
    "# Loading feature names\n",
    "feature_names= dict()\n",
    "\n",
    "for feature_type in feature_types:\n",
    "    \n",
    "    filepath = data_path + week_type + '-' + feature_type + '-' + course + '/settings.txt'\n",
    "    file = open(filepath, \"r\")\n",
    "    contents = file.read()\n",
    "    dictionary = ast.literal_eval(contents)\n",
    "    file.close()\n",
    "    \n",
    "    feature_type_name = dictionary['feature_names']\n",
    "    feature_type_name = [clean_name(x) for x in feature_type_name]\n",
    "    \n",
    "    if feature_type == 'akpinar_et_al': \n",
    "        feature_type_name = [clean_akp_name(x) for x in feature_type_name]\n",
    "        akp_mask = np.where(np.isin(feature_type_name, \n",
    "                 [\"total_clicks\", \"number_sessions\", \"time_in__video_sum\", \"time_in__problem_sum\",\n",
    "                  'problem.check-problem.check-problem.check', \n",
    "                  'problem.check-problem.check-video.load', \n",
    "                  'video.play-video.play-video.play',\n",
    "                  'video.play-video.pause-video.load',\n",
    "                  'video.play-problem.check-problem.check',\n",
    "                  'video.play-video.stop-video.play',\n",
    "                  'video.pause-video.speedchange-video.play',\n",
    "                  'video.stop-video.play-video.seek',\n",
    "                  'video.stop-problem.check-video.load']))\n",
    "#         print(akp_mask)\n",
    "        feature_type_name = list(np.array(feature_type_name)[akp_mask[0]])\n",
    "        feature_list[course][akpinar_et_al_id] = feature_list[course][akpinar_et_al_id][akp_mask[0]]\n",
    "        \n",
    "    feature_names[feature_type] = feature_type_name\n",
    "    print(feature_type, len(feature_type_name))\n",
    "\n",
    "if remove_obvious: \n",
    "    # drop 'student shape', 'competency strength', 'competency alignment' in marras at al\n",
    "    mr_mask = np.where(np.isin(feature_names['marras_et_al'], \n",
    "                 ['student_shape', 'competency_strength', 'competency_alignment']))\n",
    "    \n",
    "    new_marras = np.delete(np.array(feature_names['marras_et_al']), mr_mask[0])\n",
    "    print(new_marras)\n",
    "    feature_names['marras_et_al'] = new_marras\n",
    "    \n",
    "#     new_features = feature_list[course][1].drop(mask[0], axis=1)\n",
    "#     feature_list[course][1] = new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c7525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the labels\n",
    "feature_type = \"boroujeni_et_al\"\n",
    "filepath = data_path + week_type + '-' + feature_type + '-' + course + '/feature_labels.csv'\n",
    "labels = pd.read_csv(filepath)[\"label-pass-fail\"]\n",
    "labels[labels.shape[0]] = 1\n",
    "y = labels.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7afef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(course):\n",
    "    feature_list = []\n",
    "    selected_features = []\n",
    "    total_features = set()\n",
    "    num_weeks = 0\n",
    "    num_features = 0\n",
    "    for i,feature_type in enumerate(feature_types):\n",
    "        try:\n",
    "            filepath = data_path + week_type + '-' + feature_type + '-' + course \n",
    "            feature_current = np.load(filepath+'/feature_values.npz')['feature_values']\n",
    "\n",
    "            shape = feature_current.shape\n",
    "    #         print(shape)\n",
    "\n",
    "            if remove_obvious and feature_type=='marras_et_al':\n",
    "                feature_current = np.delete(feature_current, mr_mask[0], axis=2)\n",
    "\n",
    "            if feature_type=='akpinar_et_al':\n",
    "                akp_mask_dl = np.delete(list(range(shape[2])), akp_mask[0])\n",
    "                feature_current = np.delete(feature_current, akp_mask_dl, axis=2)\n",
    "\n",
    "            shape = feature_current.shape\n",
    "            print(shape)\n",
    "            if i==0:\n",
    "                num_weeks = shape[1]\n",
    "\n",
    "\n",
    "            selected = np.arange(shape[2])\n",
    "            # drop existed features\n",
    "            exist_mask = []\n",
    "            for i, name in enumerate(feature_names[feature_type]):\n",
    "                if name in total_features:\n",
    "                    exist_mask.append(i)\n",
    "                else:\n",
    "                    total_features.add(name)\n",
    "            feature_current = np.delete(feature_current, exist_mask, axis=2)\n",
    "            selected = np.delete(selected, exist_mask)\n",
    "\n",
    "            nonNaN = (shape[0]*shape[1] - np.isnan(feature_current.reshape(-1,feature_current.shape[2])).sum(axis=0) > 0)\n",
    "            feature_current = feature_current[:,:,nonNaN]\n",
    "            selected = selected[nonNaN]\n",
    "            feature_current = fillNaN(feature_current)\n",
    "            nonZero = (abs(feature_current.reshape(-1,feature_current.shape[2])).sum(axis=0)>0)\n",
    "            selected = selected[nonZero]\n",
    "            feature_current = feature_current[:,:,nonZero]\n",
    "    #         print(len(feature_names[feature_type]), selected)\n",
    "            selected_features.append(np.array(feature_names[feature_type])[[selected]])\n",
    "            num_features += len(np.array(feature_names[feature_type])[[selected]])\n",
    "\n",
    "\n",
    "            ##### Normalization with min-max. Added the artifical 1.001 max row for solving the same min max problem\n",
    "            ##### for features with max=0 I added 1 instead of 1.001 of maximum\n",
    "\n",
    "            features_min = feature_current.min(axis=0).reshape(-1)\n",
    "            features_max = feature_current.max(axis=0)\n",
    "            features_max = np.where(features_max==0,np.ones(features_max.shape),features_max)\n",
    "            max_instance = 1.001*features_max\n",
    "            feature_current = np.vstack([feature_current,max_instance.reshape((1,)+max_instance.shape)])\n",
    "            features_max = features_max.reshape(-1)\n",
    "            feature_norm = (feature_current.reshape(shape[0]+1,-1)-features_min)/(1.001*features_max-features_min)\n",
    "            feature_current = feature_norm.reshape(-1,feature_current.shape[1],feature_current.shape[2] )\n",
    "\n",
    "            feature_list.append(feature_current)\n",
    "        except:\n",
    "            print('{} is not valiad'.format(feature_type))\n",
    "        \n",
    "    features = np.concatenate(feature_list, axis=2)\n",
    "    features_min = features.min(axis=0).reshape(-1)\n",
    "    features_max = features.max(axis=0)\n",
    "    features = features.reshape(features.shape[0],-1)\n",
    "    features = pd.DataFrame(features)\n",
    "    \n",
    "    SHAPE = features.shape\n",
    "    # print(np.isnan(features[0,0,-1]))\n",
    "    print('features shape:', features.shape)\n",
    "    print('course: ', course)\n",
    "    print('week_type: ', week_type)\n",
    "    print('feature_type: ', feature_types)\n",
    "    print(selected_features)\n",
    "    return features, features_min, features_max, selected_features, num_weeks, num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abcc2f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2149, 15, 13)\n",
      "(2149, 15, 3)\n",
      "(2149, 15, 13)\n",
      "(2149, 15, 3)\n",
      "(2149, 15, 22)\n",
      "(2149, 15, 10)\n",
      "(2149, 15, 4)\n",
      "(2149, 15, 3)\n",
      "(2149, 15, 13)\n",
      "(2149, 15, 13)\n",
      "features shape: (2150, 990)\n",
      "course:  geomatique_003\n",
      "week_type:  eq_week\n",
      "feature_type:  ['akpinar_et_al', 'boroujeni_et_al', 'chen_cui', 'he_et_al', 'lalle_conati', 'lemay_doleck', 'marras_et_al', 'mbouzao_et_al', 'mubarak_et_al', 'wan_et_al']\n",
      "[array(['total_clicks', 'number_sessions', 'time_in__video_sum',\n",
      "       'time_in__problem_sum', 'video.pause-video.speedchange-video.play',\n",
      "       'video.play-video.pause-video.load',\n",
      "       'video.play-video.play-video.play',\n",
      "       'video.play-problem.check-problem.check',\n",
      "       'problem.check-problem.check-video.load',\n",
      "       'problem.check-problem.check-problem.check'], dtype='<U41'), array(['regularity_peak_dayhour', 'regularity_periodicity_m1',\n",
      "       'delay_lecture'], dtype='<U25'), array(['time_sessions_sum', 'time_sessions_mean',\n",
      "       'time_between_sessions_std', 'time_sessions_std',\n",
      "       'total_clicks_weekday', 'total_clicks_weekend',\n",
      "       'ratio_clicks_weekend_day', 'total_clicks_video',\n",
      "       'total_clicks_problem'], dtype='<U25'), array(['attendance_rate', 'utilization_rate', 'watching_ratio'],\n",
      "      dtype='<U16'), array(['total_clicks_Video.Load', 'weekly_prop_watched_mean',\n",
      "       'weekly_prop_replayed_mean', 'weekly_prop_interrupted_mean',\n",
      "       'total_clicks_Video', 'frequency_action_Video',\n",
      "       'frequency_action_Video.Load', 'frequency_action_Video.Play',\n",
      "       'frequency_action_Video.Pause', 'pause_duration_mean',\n",
      "       'pause_duration_std', 'time_speeding_up_mean',\n",
      "       'time_speeding_up_std'], dtype='<U35'), array(['fraction_spent_ratio_duration_Video.Play',\n",
      "       'fraction_spent_ratio_played_Video.Pause',\n",
      "       'fraction_spent_completed_Video.Play',\n",
      "       'fraction_spent_spent_Video.Play',\n",
      "       'frequency_action_total_Video.Pause', 'speed_playback__mean',\n",
      "       'speed_playback__std', 'count_unique_elements_video'], dtype='<U41'), array(['competency_anticipation', 'content_alignment',\n",
      "       'content_anticipation', 'student_speed'], dtype='<U23'), array(['watching_index'], dtype='<U16'), array(['fraction_spent_entirety_Video.Play',\n",
      "       'frequency_action_relative_Video.Play',\n",
      "       'frequency_action_relative_Video.Pause',\n",
      "       'frequency_action_relative_Video.Load'], dtype='<U41'), array(['number_submissions_distinct', 'number_submissions',\n",
      "       'number_submissions_distinct_correct', 'number_submissions_avg',\n",
      "       'obs_duration_problem', 'number_submissions_perc_correct',\n",
      "       'time_solve_problem', 'obs_duration_problem_var',\n",
      "       'obs_duration_problem_amax', 'time_sessions_length',\n",
      "       'number_submissions_correct'], dtype='<U35')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/16/kn9v95ss6kx75q2kjs2mn9jm0000gn/T/ipykernel_98908/901995784.py:47: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  selected_features.append(np.array(feature_names[feature_type])[[selected]])\n",
      "/var/folders/16/kn9v95ss6kx75q2kjs2mn9jm0000gn/T/ipykernel_98908/901995784.py:48: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  num_features += len(np.array(feature_names[feature_type])[[selected]])\n"
     ]
    }
   ],
   "source": [
    "features, features_min, features_max, selected_features, n_weeks, n_features = load_features(course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687bcbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'akpinar_et_al': ['total_clicks', 'number_sessions', 'time_in__video_sum', 'time_in__problem_sum', 'video.pause-video.speedchange-video.play', 'video.play-video.pause-video.load', 'video.play-video.play-video.play', 'video.play-problem.check-problem.check', 'problem.check-problem.check-video.load', 'problem.check-problem.check-problem.check'], 'boroujeni_et_al': ['regularity_peak_dayhour', 'regularity_periodicity_m1', 'delay_lecture'], 'chen_cui': ['time_sessions_sum', 'time_sessions_mean', 'time_between_sessions_std', 'time_sessions_std', 'total_clicks_weekday', 'total_clicks_weekend', 'ratio_clicks_weekend_day', 'total_clicks_video', 'total_clicks_problem'], 'he_et_al': ['attendance_rate', 'utilization_rate', 'watching_ratio'], 'lalle_conati': ['total_clicks_Video.Load', 'weekly_prop_watched_mean', 'weekly_prop_replayed_mean', 'weekly_prop_interrupted_mean', 'total_clicks_Video', 'frequency_action_Video', 'frequency_action_Video.Load', 'frequency_action_Video.Play', 'frequency_action_Video.Pause', 'pause_duration_mean', 'pause_duration_std', 'time_speeding_up_mean', 'time_speeding_up_std'], 'lemay_doleck': ['fraction_spent_ratio_duration_Video.Play', 'fraction_spent_ratio_played_Video.Pause', 'fraction_spent_completed_Video.Play', 'fraction_spent_spent_Video.Play', 'frequency_action_total_Video.Pause', 'speed_playback__mean', 'speed_playback__std', 'count_unique_elements_video'], 'marras_et_al': ['competency_anticipation', 'content_alignment', 'content_anticipation', 'student_speed'], 'mbouzao_et_al': ['watching_index'], 'mubarak_et_al': ['fraction_spent_entirety_Video.Play', 'frequency_action_relative_Video.Play', 'frequency_action_relative_Video.Pause', 'frequency_action_relative_Video.Load'], 'wan_et_al': ['number_submissions_distinct', 'number_submissions', 'number_submissions_distinct_correct', 'number_submissions_avg', 'obs_duration_problem', 'number_submissions_perc_correct', 'time_solve_problem', 'obs_duration_problem_var', 'obs_duration_problem_amax', 'time_sessions_length', 'number_submissions_correct']}\n"
     ]
    }
   ],
   "source": [
    "# make feature names more readable\n",
    "# ex: time_in__problem_<function sum at 0x7f3bd02cc9d0> -> time_in_problem_sum\n",
    "def clean_name(feature):\n",
    "    id = feature.find('<')\n",
    "    if id==-1:\n",
    "        return feature\n",
    "    fct = feature[id+9:id+14].strip()\n",
    "    return feature[0:id]+fct\n",
    "\n",
    "\n",
    "cleaned_selected_features = dict()\n",
    "\n",
    "for i,feature_type in enumerate(feature_types):\n",
    "    cleaned_features = [clean_name(x) for x in selected_features[i]]\n",
    "    cleaned_selected_features[feature_type] = cleaned_features\n",
    "\n",
    "selected_features = cleaned_selected_features\n",
    "print(selected_features)\n",
    "# file = 'selected_features/' + course + '_after.json'\n",
    "# with open(file, 'w') as f: \n",
    "#     json.dump(selected_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85f7895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 3, 9, 3, 13, 8, 4, 1, 4, 11]\n"
     ]
    }
   ],
   "source": [
    "num_feature_type = []\n",
    "for i, feature_type in enumerate(feature_types):\n",
    "    num_feature_type.append(len(selected_features[feature_type]))\n",
    "print(num_feature_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7475ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading feature names and transforming them to 2D format.\n",
    "feature_names= []\n",
    "final_features = []\n",
    "for feature_type in feature_types:\n",
    "    [final_features.append(x) for x in selected_features[feature_type]]\n",
    "for i in np.arange(n_weeks):\n",
    "    feature_type_name_with_weeks = [(x+'_InWeek'+str(i+1)) for x in final_features]\n",
    "    feature_names.append(feature_type_name_with_weeks)\n",
    "feature_names = np.concatenate(feature_names, axis=0)\n",
    "feature_names = feature_names.reshape(-1)\n",
    "# print(feature_names)\n",
    "features.columns = feature_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c27df",
   "metadata": {},
   "source": [
    "## Making a predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14619002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module transforms our data to the 2D format biLSTM was trained with.\n",
    "def transform_x(x, num_feature_type, num_weeks, features_min, features_max, normal=True):\n",
    "    return np.array(x).reshape((x.shape[0],x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115be155",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 09:46:11.172107: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-15 09:46:12.435708: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:13.887068: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:14.475816: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:15.716196: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:15.729680: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:16.655390: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:16.668111: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:17.071577: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:17.097697: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:17.676818: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:17.689000: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:17.748690: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:17.760645: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.152483: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.166135: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.328884: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.341550: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.778332: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.791221: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.811840: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.885282: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:18.899293: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:19.561444: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-06-15 09:46:19.574154: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "# EDIT HERE FOR OTHER MODELS\n",
    "model_path = '../models/'\n",
    "model_name = model_path + \"lstm_bi_\"+course\n",
    "loaded_model = keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a68d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 14, 82)            0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 14, 82)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 14, 128)          75264     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,545\n",
      "Trainable params: 116,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bae84608",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict(\n",
    "    transform_x(np.array(features), \n",
    "                num_feature_type, n_weeks, \n",
    "                features_min=features_min, \n",
    "                features_max=features_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7b045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2150, 1) (2150,) (2150, 990)\n"
     ]
    }
   ],
   "source": [
    "print(prediction.shape, y.shape, features.shape)\n",
    "features_with_prediction = features.copy()\n",
    "features_with_prediction[\"prediction\"] = prediction\n",
    "features_with_prediction[\"real_label\"] = y\n",
    "features_with_prediction[\"abs_difference\"] = abs(\n",
    "    features_with_prediction[\"prediction\"].values\n",
    "    - features_with_prediction[\"real_label\"].values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "932b200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_instances = y > 0\n",
    "failed = features_with_prediction.iloc[failed_instances]\n",
    "failed = failed.sort_values(by=\"abs_difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "308631dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_instances = y < 1\n",
    "passed = features_with_prediction.iloc[passed_instances]\n",
    "passed = passed.sort_values(by=\"abs_difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d16864",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_p = passed.iloc[\n",
    "    (np.ceil(np.linspace(0, passed.shape[0] - 1, num_p)))\n",
    "].index.values\n",
    "chosen_f = failed.iloc[\n",
    "    (np.ceil(np.linspace(0, failed.shape[0] - 1, num_f)))\n",
    "].index.values\n",
    "instances = np.concatenate((chosen_f, chosen_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "326f41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"uniform_data/uniform_\" + course, instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d957e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
